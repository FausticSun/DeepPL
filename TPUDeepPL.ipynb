{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TPUDeepPL.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "kPfASqjPXwvg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Initialization"
      ]
    },
    {
      "metadata": {
        "id": "mNRBIHV3ec3z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Tensorboard support"
      ]
    },
    {
      "metadata": {
        "id": "bzSOwzBRwMgS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rW2Sa5q9wPPs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LOG_DIR = './logs'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "laof22xr8JND",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Perform imports"
      ]
    },
    {
      "metadata": {
        "id": "xpVY3OIj8Kba",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow.keras.backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.keras.layers import Input, Conv3D, MaxPooling3D,Flatten,Dense, Dropout, BatchNormalization, Add, AveragePooling3D, Activation, GaussianNoise, Lambda\n",
        "from tensorflow.keras import optimizers, losses, regularizers\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.initializers import glorot_normal\n",
        "from tensorflow.keras.utils import plot_model, Sequence\n",
        "from tensorflow.keras.activations import relu\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
        "from tensorflow.train import AdamOptimizer, GradientDescentOptimizer, MomentumOptimizer\n",
        "from tensorflow.contrib.opt import AdamWOptimizer\n",
        "from tensorflow.contrib.tpu import CrossShardOptimizer\n",
        "from IPython.display import SVG\n",
        "from sklearn.metrics import confusion_matrix, matthews_corrcoef\n",
        "from tqdm import tqdm, trange\n",
        "import tensorflow as tf\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fSp4mjx75ovC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Define util functions"
      ]
    },
    {
      "metadata": {
        "id": "CU5PBkYc5oBN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Reads a up to spec pdb file and return a tuple of the\n",
        "# atoms' x, y, z and atomtype\n",
        "def read_pdb(filename):\n",
        "    with open(filename, 'r') as file:\n",
        "        strline_L = file.readlines()\n",
        "    atom_list = []\n",
        "    for strline in strline_L:\n",
        "        # removes all whitespace at the start and end, including spaces, tabs, newlines and carriage returns\n",
        "        stripped_line = strline.strip()\n",
        "\n",
        "        line_length = len(stripped_line)\n",
        "        # print(\"Line length:{}\".format(line_length))\n",
        "        if line_length < 78:\n",
        "            print(\"ERROR: line length is different. Expected>=78, current={}\".format(line_length))\n",
        "        \n",
        "        atom_list.append((\n",
        "            stripped_line[30:38].strip(),\n",
        "            stripped_line[38:46].strip(),\n",
        "            stripped_line[46:54].strip(),\n",
        "            'h' if stripped_line[76:78].strip() == 'C' else 'p',\n",
        "        ))\n",
        "        \n",
        "    return np.array(atom_list, order='F')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rX5pAtkB6XCY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Reads the test pdb file and return a tuple of the\n",
        "# atoms' x, y, z and atomtype\n",
        "def read_test_pdb(filename):\n",
        "    with open(filename, 'r') as file:\n",
        "        strline_L = file.readlines()\n",
        "    atom_list = []\n",
        "    for strline in strline_L:\n",
        "        # removes all whitespace at the start and end, including spaces, tabs, newlines and carriage returns\n",
        "        stripped_line = strline.strip()\n",
        "        tokens = stripped_line.split(\"\\t\")\n",
        "        \n",
        "        atom_list.append((\n",
        "            tokens[0],\n",
        "            tokens[1],\n",
        "            tokens[2],\n",
        "            tokens[3],\n",
        "        ))\n",
        "\n",
        "    return np.array(atom_list, order='F')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KbQYmIcjMEUx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iF6-CnlNKL51",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def mcc(y_true, y_pred):\n",
        "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
        "    y_pred_neg = 1 - y_pred_pos\n",
        "\n",
        "    y_pos = K.round(K.clip(y_true, 0, 1))\n",
        "    y_neg = 1 - y_pos\n",
        "\n",
        "    tp = K.sum(y_pos * y_pred_pos)\n",
        "    tn = K.sum(y_neg * y_pred_neg)\n",
        "\n",
        "    fp = K.sum(y_neg * y_pred_pos)\n",
        "    fn = K.sum(y_pos * y_pred_neg)\n",
        "\n",
        "    numerator = (tp * tn - fp * fn)\n",
        "    denominator = K.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
        "\n",
        "    return numerator / (denominator + K.epsilon())\n",
        "\n",
        "def ppv(y_true, y_pred):\n",
        "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
        "    y_pred_neg = 1 - y_pred_pos\n",
        "\n",
        "    y_pos = K.round(K.clip(y_true, 0, 1))\n",
        "    y_neg = 1 - y_pos\n",
        "\n",
        "    tp = K.sum(y_pos * y_pred_pos)\n",
        "    tn = K.sum(y_neg * y_pred_neg)\n",
        "\n",
        "    fp = K.sum(y_neg * y_pred_pos)\n",
        "    fn = K.sum(y_pos * y_pred_neg)\n",
        "\n",
        "    numerator = tp\n",
        "    denominator = tp + fp\n",
        "\n",
        "    return numerator / (denominator + K.epsilon())\n",
        "\n",
        "def tpr(y_true, y_pred):\n",
        "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
        "    y_pred_neg = 1 - y_pred_pos\n",
        "\n",
        "    y_pos = K.round(K.clip(y_true, 0, 1))\n",
        "    y_neg = 1 - y_pos\n",
        "\n",
        "    tp = K.sum(y_pos * y_pred_pos)\n",
        "    tn = K.sum(y_neg * y_pred_neg)\n",
        "\n",
        "    fp = K.sum(y_neg * y_pred_pos)\n",
        "    fn = K.sum(y_pos * y_pred_neg)\n",
        "\n",
        "    numerator = tp\n",
        "    denominator = tp + fn\n",
        "\n",
        "    return numerator / (denominator + K.epsilon())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AMgEKZ1z4ydt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Import raw training data"
      ]
    },
    {
      "metadata": {
        "id": "3u12bJmi5ZQT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Download and unzip the training data"
      ]
    },
    {
      "metadata": {
        "id": "tT5JBRlt5X9V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget https://web.bii.a-star.edu.sg/~leehk/cs5242_project/training_data.zip\n",
        "!unzip training_data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3jTil3Yg6neI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load training data into memory"
      ]
    },
    {
      "metadata": {
        "id": "w3ZWUsIa5iN9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "raw_training_data = {\n",
        "    'pro': [],\n",
        "    'lig': []\n",
        "}\n",
        "for i in trange(3000):\n",
        "    raw_training_data['pro'].append(\n",
        "        read_pdb(\"./training_data/{:04d}_pro_cg.pdb\".format(i + 1)))\n",
        "    raw_training_data['lig'].append(\n",
        "        read_pdb(\"./training_data/{:04d}_lig_cg.pdb\".format(i + 1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HGs_6EpYJrZJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n = int(len(raw_training_data['pro'])*0.9)\n",
        "raw_training_train_data = {\n",
        "    'pro': raw_training_data['pro'][:n],\n",
        "    'lig': raw_training_data['lig'][:n]\n",
        "}\n",
        "raw_training_test_data = {\n",
        "    'pro': raw_training_data['pro'][n:],\n",
        "    'lig': raw_training_data['lig'][n:]\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fNCR-RG_ZOsc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Preprocess training data"
      ]
    },
    {
      "metadata": {
        "id": "pZS6ACn2KqkG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Install multidimensional sparse matrix library"
      ]
    },
    {
      "metadata": {
        "id": "y74Bqu97KumN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install sparse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w05VtPMJLw_Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sparse import COO\n",
        "import sparse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RmOpSKmd9lwv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Define voxelization functions"
      ]
    },
    {
      "metadata": {
        "id": "feaONl2zONBH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Returns a sparse matrix representation of the voxel\n",
        "def voxelize(pdb_inputs, max_dist=20, grid_resolution=4):\n",
        "    def featurize(atom_type):\n",
        "        # Default: protein, hydrophobic\n",
        "        feat = [0, 128]\n",
        "        # Change to ligand\n",
        "        if atom_type[1] == 'l':\n",
        "            feat[0] = 1\n",
        "        # change to polar\n",
        "        if atom_type[0] == 'p':\n",
        "            feat[1] = 256\n",
        "        return feat\n",
        "    \n",
        "    max_dist = float(max_dist)\n",
        "    grid_resolution = float(grid_resolution)\n",
        "    box_size = np.ceil(2 * max_dist / grid_resolution + 1)\n",
        "\n",
        "    # merge protein and ligand\n",
        "    pro_atoms = pdb_inputs[0]\n",
        "    lig_atoms = pdb_inputs[1]\n",
        "    pro_atoms = np.c_[pro_atoms, np.full(pro_atoms.shape[0], 'p')]\n",
        "    lig_atoms = np.c_[lig_atoms, np.full(lig_atoms.shape[0], 'l')]\n",
        "    all_atoms = np.r_[pro_atoms, lig_atoms]\n",
        "\n",
        "    # center all atoms around the center of the protein\n",
        "    coord_mat = all_atoms[:,:3].astype(np.float)\n",
        "    coord_mat = coord_mat - np.mean(lig_atoms[:,:3].astype(np.float), axis=0)\n",
        "\n",
        "    # add feature list to identify the atom h/p and pro/lig\n",
        "    feats_list = np.asarray([featurize(atom_type) for atom_type in all_atoms[:,-2:]])  \n",
        "    atom_mat = np.c_[coord_mat, feats_list]\n",
        "\n",
        "    # move all atoms to the nearest grid point\n",
        "    atom_mat = np.c_[coord_mat, feats_list]\n",
        "    atom_mat[:,:3] = (atom_mat[:,:3] + max_dist) / grid_resolution\n",
        "    atom_mat[:,:3] = atom_mat[:,:3].round()\n",
        "    atom_mat = atom_mat.astype(int)\n",
        "\n",
        "    # remove atoms outside the box\n",
        "    in_box = ((atom_mat[:,:3] >= 0) & (atom_mat[:,:3] < box_size)).all(axis=1)\n",
        "    atom_mat = atom_mat[in_box]\n",
        "\n",
        "    # transpose the matrix\n",
        "    feats_list = np.squeeze(atom_mat[:,-1:])\n",
        "    atom_mat = atom_mat[:,:4].T\n",
        "    \n",
        "    # create the sparse matrix\n",
        "    s = COO(atom_mat, feats_list, shape=(int(box_size), int(box_size), int(box_size), 2))\n",
        "    s.sum()\n",
        "    s = s.reshape((1, int(box_size), int(box_size), int(box_size), 2))\n",
        "    \n",
        "    return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NCjgvjon-l8H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Returns a tuple containg the training data and corresponding labels\n",
        "# ratio specifies the number of negative training examples generated\n",
        "# per positive training example\n",
        "def generate_training_data(raw_data, pos_ratio=1, neg_ratio=1, max_dist=20, grid_resolution=4, quiet=False):\n",
        "    n = len(raw_data['pro'])\n",
        "    x_all = []\n",
        "    y_all = []\n",
        "    for i in tqdm(range(n), disable=quiet):\n",
        "        for _ in range(pos_ratio):\n",
        "            grid = voxelize((\n",
        "                raw_data['pro'][i],\n",
        "                raw_data['lig'][i]\n",
        "            ), max_dist, grid_resolution)\n",
        "            x_all.append(grid)\n",
        "            y_all.append([1.])\n",
        "        for _ in range(neg_ratio):\n",
        "            grid = voxelize((\n",
        "                raw_data['pro'][i],\n",
        "                raw_data['lig'][random.choice(list(range(i)) + list(range(i+1, n)))]\n",
        "            ), max_dist, grid_resolution)\n",
        "            x_all.append(grid)\n",
        "            y_all.append([0.])\n",
        "    return sparse.concatenate(x_all), np.asarray(y_all)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gRkntlc6N-SU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Define Keras Sequence for dymanically generating samples\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "8JjffQmKOE1R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ProLigSequence(Sequence):\n",
        "\n",
        "    def __init__(self, raw_data, max_dist=20, grid_resolution=4, batch_size=128, neg_ratio=1, quiet=True, sparse=True):\n",
        "        self.raw_data = raw_data\n",
        "        self.max_dist = max_dist\n",
        "        self.grid_resolution = grid_resolution\n",
        "        self.batch_size = batch_size\n",
        "        self.neg_ratio = neg_ratio\n",
        "        self.quiet = quiet\n",
        "        self.sparse = sparse\n",
        "        self.pos_eg_x, self.pos_eg_y = generate_training_data(raw_data, neg_ratio=0, max_dist=max_dist, grid_resolution=grid_resolution, quiet=self.quiet)\n",
        "        if not sparse:\n",
        "            self.pos_eg_x = self.pos_eg_x.todense()\n",
        "        self.on_epoch_end()\n",
        "        \n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.all_eg_x) / float(self.batch_size)))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        indexes = self.indexes[idx*self.batch_size:(idx+1)*self.batch_size]\n",
        "        batch_x = self.all_eg_x[indexes].todense() if self.sparse else self.all_eg_x[indexes]\n",
        "        batch_y = self.all_eg_y[indexes]\n",
        "        return batch_x, batch_y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        # Generate a new set of negative training examples\n",
        "        self.neg_eg_x, self.neg_eg_y = generate_training_data(\n",
        "            self.raw_data,\n",
        "            pos_ratio=0,\n",
        "            neg_ratio=self.neg_ratio,\n",
        "            max_dist=self.max_dist,\n",
        "            grid_resolution=self.grid_resolution,\n",
        "            quiet=self.quiet\n",
        "        )\n",
        "        if self.sparse:\n",
        "            self.all_eg_x = sparse.concatenate((self.pos_eg_x, self.neg_eg_x))\n",
        "        else:\n",
        "            self.all_eg_x = np.concatenate((self.pos_eg_x, self.neg_eg_x.todense()))\n",
        "        self.all_eg_y = np.concatenate((self.pos_eg_y, self.neg_eg_y))\n",
        "        self.indexes = np.arange(len(self.all_eg_x))\n",
        "        np.random.shuffle(self.indexes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HM-D13Q6CdOG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Define Wide ResNet"
      ]
    },
    {
      "metadata": {
        "id": "UUJwN6JVCnSJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# k defines the width of the network as defined in the Wide ResNet paper\n",
        "def generate_resnet(input_shape, k=1, noise=False,\n",
        "                    l1_filters=16, l1_kernel_size=3, l1_dilation_rate=1):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = inputs\n",
        "    x = Conv3D(\n",
        "        filters=l1_filters,\n",
        "        kernel_size=l1_kernel_size,\n",
        "        dilation_rate=l1_dilation_rate,\n",
        "        padding='valid',\n",
        "        data_format='channels_last',\n",
        "        kernel_initializer='he_normal',\n",
        "    )(x)\n",
        "    \n",
        "    # Block 1.1 32 Features\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x2 = Conv3D(\n",
        "        filters=32*k,\n",
        "        kernel_size=1,\n",
        "        padding='same',\n",
        "        data_format='channels_last',\n",
        "        kernel_initializer='he_normal',\n",
        "    )(x)\n",
        "    x1 = Conv3D(\n",
        "        filters=32*k,\n",
        "        kernel_size=3,\n",
        "        padding='same',\n",
        "        data_format='channels_last',\n",
        "        kernel_initializer='he_normal',\n",
        "    )(x)\n",
        "    x1 = Dropout(0.5)(x1)\n",
        "    x1 = BatchNormalization()(x1)\n",
        "    x1 = Activation('relu')(x1)\n",
        "    x1 = Conv3D(\n",
        "        filters=32*k,\n",
        "        kernel_size=3,\n",
        "        padding='same',\n",
        "        data_format='channels_last',\n",
        "        kernel_initializer='he_normal',\n",
        "    )(x1)\n",
        "    x = Add()([x1, x2])\n",
        "\n",
        "    # Block 1.2 32 Features\n",
        "    x2 = x\n",
        "    x1 = BatchNormalization()(x)\n",
        "    x1 = Activation('relu')(x1)\n",
        "    x1 = Conv3D(\n",
        "        filters=32*k,\n",
        "        kernel_size=3,\n",
        "        padding='same',\n",
        "        data_format='channels_last',\n",
        "        kernel_initializer='he_normal',\n",
        "    )(x1)\n",
        "    x1 = Dropout(0.5)(x1)\n",
        "    x1 = BatchNormalization()(x1)\n",
        "    x1 = Activation('relu')(x1)\n",
        "    x1 = Conv3D(\n",
        "        filters=32*k,\n",
        "        kernel_size=3,\n",
        "        padding='same',\n",
        "        data_format='channels_last',\n",
        "        kernel_initializer='he_normal',\n",
        "    )(x1)\n",
        "    x = Add()([x1, x2])\n",
        "\n",
        "    # Block 2.1 64 Features\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x2 = Conv3D(\n",
        "        filters=64*k,\n",
        "        kernel_size=1,\n",
        "        padding='same',\n",
        "        data_format='channels_last',\n",
        "        kernel_initializer='he_normal',\n",
        "    )(x)\n",
        "    x1 = Conv3D(\n",
        "        filters=64*k,\n",
        "        kernel_size=3,\n",
        "        padding='same',\n",
        "        data_format='channels_last',\n",
        "        kernel_initializer='he_normal',\n",
        "    )(x)\n",
        "    x1 = Dropout(0.5)(x1)\n",
        "    x1 = BatchNormalization()(x1)\n",
        "    x1 = Activation('relu')(x1)\n",
        "    x1 = Conv3D(\n",
        "        filters=64*k,\n",
        "        kernel_size=3,\n",
        "        padding='same',\n",
        "        data_format='channels_last',\n",
        "        kernel_initializer='he_normal',\n",
        "    )(x1)\n",
        "    x = Add()([x1, x2])\n",
        "\n",
        "    # Block 2.2 64 Features\n",
        "    x2 = x\n",
        "    x1 = BatchNormalization()(x)\n",
        "    x1 = Activation('relu')(x1)\n",
        "    x1 = Conv3D(\n",
        "        filters=64*k,\n",
        "        kernel_size=3,\n",
        "        padding='same',\n",
        "        data_format='channels_last',\n",
        "        kernel_initializer='he_normal',\n",
        "    )(x1)\n",
        "    x1 = Dropout(0.5)(x1)\n",
        "    x1 = BatchNormalization()(x1)\n",
        "    x1 = Activation('relu')(x1)\n",
        "    x1 = Conv3D(\n",
        "        filters=64*k,\n",
        "        kernel_size=3,\n",
        "        padding='same',\n",
        "        data_format='channels_last',\n",
        "        kernel_initializer='he_normal',\n",
        "    )(x1)\n",
        "    x = Add()([x1, x2])    \n",
        "    \n",
        "    # Block 3.1 128 Features\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x2 = Conv3D(\n",
        "        filters=128*k,\n",
        "        kernel_size=1,\n",
        "        padding='same',\n",
        "        data_format='channels_last',\n",
        "        kernel_initializer='he_normal',\n",
        "    )(x)\n",
        "    x1 = Conv3D(\n",
        "        filters=128*k,\n",
        "        kernel_size=3,\n",
        "        padding='same',\n",
        "        data_format='channels_last',\n",
        "        kernel_initializer='he_normal',\n",
        "    )(x)\n",
        "    x1 = Dropout(0.5)(x1)\n",
        "    x1 = BatchNormalization()(x1)\n",
        "    x1 = Activation('relu')(x1)\n",
        "    x1 = Conv3D(\n",
        "        filters=128*k,\n",
        "        kernel_size=3,\n",
        "        padding='same',\n",
        "        data_format='channels_last',\n",
        "        kernel_initializer='he_normal',\n",
        "    )(x1)\n",
        "    x = Add()([x1, x2])\n",
        "\n",
        "    # Block 3.2 128 Features\n",
        "    x2 = x\n",
        "    x1 = BatchNormalization()(x)\n",
        "    x1 = Activation('relu')(x1)\n",
        "    x1 = Conv3D(\n",
        "        filters=128*k,\n",
        "        kernel_size=3,\n",
        "        padding='same',\n",
        "        data_format='channels_last',\n",
        "        kernel_initializer='he_normal',\n",
        "    )(x1)\n",
        "    x1 = Dropout(0.5)(x1)\n",
        "    x1 = BatchNormalization()(x1)\n",
        "    x1 = Activation('relu')(x1)\n",
        "    x1 = Conv3D(\n",
        "        filters=128*k,\n",
        "        kernel_size=3,\n",
        "        padding='same',\n",
        "        data_format='channels_last',\n",
        "        kernel_initializer='he_normal',\n",
        "    )(x1)\n",
        "    x = Add()([x1, x2])      \n",
        "    \n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = AveragePooling3D()(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(\n",
        "        128,\n",
        "        activation='relu',\n",
        "        kernel_initializer='he_normal',\n",
        "    )(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    outputs = Dense(\n",
        "        1,\n",
        "        activation='sigmoid',\n",
        "        kernel_initializer='he_normal',\n",
        "    )(x)\n",
        "\n",
        "    return Model(inputs=inputs, outputs=outputs)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PEJKuSlj2i7P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = generate_resnet(\n",
        "    input_shape=(21, 21, 21, 2),\n",
        "    k=1,\n",
        "    l1_filters=16,\n",
        "    l1_kernel_size=6,\n",
        "    l1_dilation_rate=3,\n",
        ")\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1N2W6iUu7LF7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tpu_model = tf.contrib.tpu.keras_to_tpu_model(\n",
        "    model,\n",
        "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "        tf.contrib.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "    )\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ULCv2l26d4-y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tpu_model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['acc', mcc, ppv, tpr],\n",
        "    optimizer=CrossShardOptimizer(AdamOptimizer())\n",
        ")\n",
        "history = tpu_model.fit_generator(\n",
        "    generator=ProLigSequence(raw_training_train_data, batch_size=512, max_dist=40, grid_resolution=4, sparse=False),\n",
        "    validation_data=ProLigSequence(raw_training_test_data, batch_size=512, max_dist=40, grid_resolution=4, sparse=False),\n",
        "    epochs=500,\n",
        "    initial_epoch=0,\n",
        "    use_multiprocessing=True,\n",
        "    workers=8,\n",
        "    callbacks=[ModelCheckpoint('Dynamic.h5',\n",
        "                           monitor='val_mcc',\n",
        "                           verbose=1,\n",
        "                           save_best_only=True,\n",
        "                           mode='max',\n",
        "                           period=1),\n",
        "              TensorBoard()]\n",
        ")\n",
        "# tpu_model.compile(\n",
        "#     loss='binary_crossentropy',\n",
        "#     metrics=['acc', mcc],\n",
        "#     optimizer=CrossShardOptimizer(MomentumOptimizer(\n",
        "#         learning_rate=0.1,\n",
        "#         momentum=0.9,\n",
        "#         use_nesterov=True))\n",
        "# )\n",
        "# tpu_model.fit_generator(\n",
        "#     generator=ProLigSequence(raw_training_train_data, batch_size=512, max_dist=50, grid_resolution=1),\n",
        "#     validation_data=ProLigSequence(raw_training_test_data, batch_size=512, max_dist=50, grid_resolution=1),\n",
        "#     epochs=2800,\n",
        "#     initial_epoch=200,\n",
        "#     use_multiprocessing=True,\n",
        "#     workers=1,\n",
        "#     callbacks=[ModelCheckpoint('Dynamic.h5',\n",
        "#                            monitor='val_mcc',\n",
        "#                            verbose=1,\n",
        "#                            save_best_only=True,\n",
        "#                            mode='max',\n",
        "#                            period=1),\n",
        "#               TensorBoard()]\n",
        "# )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ER_DyjMwODxW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Evaluate Model"
      ]
    },
    {
      "metadata": {
        "id": "jJFecNvcOMl9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Generate testing data"
      ]
    },
    {
      "metadata": {
        "id": "dL_1otRr6EIM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_test, y_test = generate_training_data(raw_training_test_data, neg_ratio=10, max_dist=40, grid_resolution=4)\n",
        "x_test = x_test.todense()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nCqKAJYmOOxS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load best model"
      ]
    },
    {
      "metadata": {
        "id": "qkaA2FDj6yPX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "best_model = load_model(\"Dynamic.h5\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hjhx8ujdOTtq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Plot confusion matrix"
      ]
    },
    {
      "metadata": {
        "id": "zTMoaV6o6H00",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred = best_model.predict(x_test)\n",
        "y_pred = np.piecewise(y_pred, [y_pred < 0.5, y_pred >= 0.5], [0., 1.])\n",
        "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cnf_matrix, classes=[0, 1], normalize=True,\n",
        "                      title='Normalized confusion matrix')\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}